{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 18:37:38.831133: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734143858.843733 1269875 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734143858.847616 1269875 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-13 18:37:38.861620: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9322127107563411963\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 48940515328\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 195851756200034454\n",
      "physical_device_desc: \"device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "WARNING:tensorflow:From /tmp/ipykernel_1269875/3273318649.py:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Is GPU available? True\n",
      "1 GPU(s) are configured for use.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734143861.029454 1269875 gpu_device.cc:2022] Created device /device:GPU:0 with 46673 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "I0000 00:00:1734143861.033019 1269875 gpu_device.cc:2022] Created device /device:GPU:0 with 46673 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "gpu_ids = [3]\n",
    "\n",
    "# Set CUDA_VISIBLE_DEVICES to use GPUs 1 and 3\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, gpu_ids))\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Check if GPU is available\n",
    "print('Available devices:', device_lib.list_local_devices())\n",
    "print('Is GPU available?', tf.test.is_gpu_available())\n",
    "\n",
    "# Set memory growth to prevent OOM errors\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f'{len(gpus)} GPU(s) are configured for use.')\n",
    "    except RuntimeError as e:\n",
    "        print(e) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import *\n",
    "from keras.src.utils import load_img, array_to_img\n",
    "from keras.src import *\n",
    "from keras.src.models import *\n",
    "from keras.src.utils import *\n",
    "from keras.api.metrics import AUC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.ops.image_ops_impl import per_image_standardization\n",
    "from keras.src.utils import file_utils\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import csv\n",
    "import os\n",
    "gpu_ids = [3]\n",
    "\n",
    "# Set CUDA_VISIBLE_DEVICES to make PyTorch see only these GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, gpu_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_WEIGHTS_PATH = (\n",
    "    \"https://storage.googleapis.com/tensorflow/keras-applications/densenet/\"\n",
    ")\n",
    "\n",
    "DENSENET169_WEIGHT_PATH_NO_TOP = (\n",
    "    BASE_WEIGHTS_PATH\n",
    "    + \"densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    ")\n",
    "\n",
    "\n",
    "#body_site = \"HUMERUS\"\n",
    "\n",
    "#Resize the image to 96*96\n",
    "\n",
    "image_size = (224,224)\n",
    "\n",
    "#Load images as RGB, remember Image Net uses RGB!!!Not grayscale, custom CNN can use grayscale and RGB both.\n",
    "color_mode = \"rgb\"\n",
    "# color_mode = \"grayscale\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet 169 Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(x, blocks, name):\n",
    "    \"\"\"A dense block.\n",
    "\n",
    "    Args:\n",
    "        x: input tensor.\n",
    "        blocks: integer, the number of building blocks.\n",
    "        name: string, block label.\n",
    "\n",
    "    Returns:\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    for i in range(blocks):\n",
    "\n",
    "        x = conv_block(x, 32, name=name + str(int(i)) +\"_block\")\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, reduction, name):\n",
    "    \"\"\"A transition block.\n",
    "\n",
    "    Args:\n",
    "        x: input tensor.\n",
    "        reduction: float, compression rate at transition layers.\n",
    "        name: string, block label.\n",
    "\n",
    "    Returns:\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = -1\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name=name + \"_bn\"\n",
    "    )(x)\n",
    "    x = layers.Activation(\"relu\", name=name + \"_relu\")(x)\n",
    "    x = layers.Conv2D(\n",
    "        int(x.shape[bn_axis] * reduction),\n",
    "        1,\n",
    "        use_bias=False,\n",
    "        name=name + \"_conv\",\n",
    "    )(x)\n",
    "    x = layers.AveragePooling2D(2, strides=2, name=name + \"_pool\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(x, growth_rate, name):\n",
    "    \"\"\"A building block for a dense block.\n",
    "\n",
    "    Args:\n",
    "        x: input tensor.\n",
    "        growth_rate: float, growth rate at dense layers.\n",
    "        name: string, block label.\n",
    "\n",
    "    Returns:\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = -1\n",
    "    x1 = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name=name + \"_0_bn\"\n",
    "    )(x)\n",
    "    x1 = layers.Activation(\"relu\", name=name + \"_0_relu\")(x1)\n",
    "    x1 = layers.Conv2D(\n",
    "        4 * growth_rate, 1, use_bias=False, name=name + \"_1_conv\"\n",
    "    )(x1)\n",
    "    x1 = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name=name + \"_1_bn\"\n",
    "    )(x1)\n",
    "    x1 = layers.Activation(\"relu\", name=name + \"_1_relu\")(x1)\n",
    "    x1 = layers.Conv2D(\n",
    "        growth_rate, 3, padding=\"same\", use_bias=False, name=name + \"_2_conv\"\n",
    "    )(x1)\n",
    "    x = layers.Concatenate(axis=bn_axis, name=name + \"_concat\")([x, x1])\n",
    "    return x\n",
    "\n",
    "\n",
    "def CustomizeDenseNet(\n",
    "    input_shape=(96,96,3),\n",
    "    weights = \"imagenet\"\n",
    "):\n",
    "    blocks = [6, 12, 32, 32]\n",
    "\n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "\n",
    "    bn_axis = -1\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=False, name=\"conv1_conv\")(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name=\"conv1_bn\"\n",
    "    )(x)\n",
    "    x = layers.Activation(\"relu\", name=\"conv1_relu\")(x)\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name=\"pool1\")(x)\n",
    "\n",
    "    x = dense_block(x, blocks[0], name=\"conv2\")\n",
    "    x = transition_block(x, 0.5, name=\"pool2\")\n",
    "    x = dense_block(x, blocks[1], name=\"conv3\")\n",
    "    x = transition_block(x, 0.5, name=\"pool3\")\n",
    "    x = dense_block(x, blocks[2], name=\"conv4\")\n",
    "    x = transition_block(x, 0.5, name=\"pool4\")\n",
    "    x = dense_block(x, blocks[3], name=\"conv5\")\n",
    "\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=\"bn\")(x)\n",
    "    x = layers.Activation(\"relu\", name=\"relu\")(x)\n",
    "\n",
    "    inputs = img_input\n",
    "\n",
    "    model = Functional(inputs, x, name=\"densenet169\")\n",
    "\n",
    "    \n",
    "    if weights == \"imagenet\":\n",
    "        weights_path = file_utils.get_file(\n",
    "        \"densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "        DENSENET169_WEIGHT_PATH_NO_TOP,\n",
    "        cache_subdir=\"models\",\n",
    "        file_hash=\"b8c4d4c20dd625c148057b9ff1c1176b\",\n",
    "    )\n",
    "        model.load_weights(weights_path)\n",
    "    # elif weights is not None:\n",
    "    #     model.load_weights(weights)\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-Cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/vision/grad_cam/\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = load_img(img_path,color_mode=color_mode,target_size=(512,512))\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    #display(Image(cam_path))\n",
    "\n",
    "def save_gradcam_n(n, a, img_paths, imgs, model, lastconv, modelname, site=\"UNKNOWN\"):\n",
    "\n",
    "    for i in range(n):\n",
    "        heatmap = make_gradcam_heatmap(np.expand_dims(imgs[i],axis=0), model, lastconv)\n",
    "        pred = int(np.round(model.predict(np.expand_dims(imgs[i],axis=0))).flatten()[0])\n",
    "        save_and_display_gradcam(img_paths[i], heatmap, cam_path=\"./gradcam/\"+site+ '/' + modelname+\"_\"+str(i)+\"_\"+str(pred)+\".jpg\", alpha=a)\n",
    "\n",
    "def find_target_layer(m):\n",
    "    last_conv_layer_name = list(filter(lambda x: isinstance(x, layers.Conv2D), m.layers))[-1].name\n",
    "    return last_conv_layer_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad Cam for Grayscale boosted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_save_gradcam_n(n, a, img_paths, imgs, model, lastconv, modelname, site=\"UNKNOWN\"):\n",
    "    for i in range(n):\n",
    "        heatmap = None\n",
    "        for k in range(5):\n",
    "            hm = make_gradcam_heatmap(np.expand_dims(imgs[i],axis=0), model.models[k][0], lastconv[k])\n",
    "            if heatmap is None:\n",
    "                heatmap = 0.2 * hm\n",
    "            else:\n",
    "                heatmap += 0.2 * hm\n",
    "        pred = int(np.round(model.predict(np.expand_dims(imgs[i],axis=0))).flatten()[0])\n",
    "        save_and_display_gradcam(img_paths[i], heatmap, cam_path=\"./Adaboost_gradcam/\"+site+ '/' + modelname+\"_\"+str(i)+\"_\"+str(pred)+\".jpg\", alpha=a)\n",
    "\n",
    "def gray_find_target_layer(m):\n",
    "    layer_name = []\n",
    "    for j in range(5):\n",
    "        last_conv_layer_name = list(filter(lambda x: isinstance(x, layers.Conv2D), boosted_model.models[j][0].layers))[-1].name\n",
    "        layer_name.append(last_conv_layer_name)\n",
    "    return layer_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data by site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(body_site, image_size, color_mode):\n",
    "    '''\n",
    "    Specify body site, image size, color mode above\n",
    "\n",
    "    '''\n",
    "    #Read in path file for training set and validation set\n",
    "    train_paths = pd.read_csv('/data/home/huixian/Documents/567/MURA-v1.1/train_image_paths.csv',  header=None,names=[\"path\"])\n",
    "    val_paths = pd.read_csv('/data/home/huixian/Documents/567/MURA-v1.1/valid_image_paths.csv',header=None,names=[\"path\"])\n",
    "    #create labels to classify normal and abnormal, first intiate all to be 0\n",
    "    train_paths['label']=0\n",
    "    val_paths['label']=0\n",
    "    #if find \"positive\" in path, set the label from 0 to 1\n",
    "    train_paths.loc[train_paths['path'].str.contains('positive'),'label']=1\n",
    "    val_paths.loc[val_paths['path'].str.contains('positive'),'label']=1\n",
    "\n",
    "    #subset for body site images path\n",
    "    train_y = train_paths[train_paths['path'].str.contains(body_site)]\n",
    "    val_y = val_paths[val_paths['path'].str.contains(body_site)]\n",
    "\n",
    "    #load training images as a 4 dimentional np array\n",
    "    train_images = []\n",
    "    for path in train_y['path']:\n",
    "        img = load_img(path,target_size=image_size,color_mode=color_mode)\n",
    "        #img_arr = per_image_standardization(img_to_array(img))\n",
    "        img_arr = img_to_array(img)\n",
    "        img_arr = per_image_standardization(img_arr)\n",
    "        train_images.append(img_arr)\n",
    "    train_X = np.array(train_images)\n",
    "    print(np.shape(train_X[0]))\n",
    "    #load validation images as a 4 dimentional np array\n",
    "    val_images = []\n",
    "    for path in val_y['path']:\n",
    "        img = load_img(path,target_size=image_size,color_mode=color_mode)\n",
    "        #img_arr = per_image_standardization(img_to_array(img))\n",
    "        img_arr = img_to_array(img)\n",
    "        img_arr = per_image_standardization(img_arr)\n",
    "        val_images.append(img_arr)\n",
    "    val_X = np.array(val_images)\n",
    "\n",
    "    #set path as index (in other words, drop path column) such that only contain labels\n",
    "    train_y = train_y.set_index('path')\n",
    "    val_y = val_y.set_index('path')\n",
    "\n",
    "    #calculate number of observations and percentage\n",
    "    train_count_all = len(train_y)\n",
    "    train_count_normal = sum(train_y['label']==0)\n",
    "    train_count_abnormal = sum(train_y['label']==1)\n",
    "    train_count_percentage = round(train_count_abnormal*100/train_count_all,2)\n",
    "    val_count_all = len (val_y)\n",
    "    val_count_normal = sum(val_y['label']==0)\n",
    "    val_count_abnormal = sum(val_y['label']==1)\n",
    "    val_count_percentage = round(val_count_abnormal*100/val_count_all,2)\n",
    "\n",
    "    #print relevant information\n",
    "    print(f'We are loading {body_site} {color_mode} images with {image_size[0]}*{image_size[1]} image size.')\n",
    "    print(f'The training set has a total of {train_count_all} images, of them, {train_count_normal} are normal and {train_count_abnormal} are abnormal images, the percentage of abnormal is {train_count_percentage}%.')\n",
    "    print(f'The validation set has a total of {val_count_all} images, of them, {val_count_normal} are normal and {val_count_abnormal} are abnormal images, the percentage of abnormal is {val_count_percentage}%.')\n",
    "    print(f'The training np array X has a dimentsion of {train_X.shape}')\n",
    "    print(f'The validation np array X has a dimentsion of {val_X.shape}')\n",
    "    print(f'The training label y has a dimentsion of {train_y.shape}')\n",
    "    print(f'The validation label y has a dimentsion of {val_y.shape}')\n",
    "    return train_X, train_y, val_X, val_y\n",
    "\n",
    "def load_val_data(body_site, image_size, color_mode):\n",
    "    '''\n",
    "    Specify body site, image size, color mode above\n",
    "\n",
    "    '''\n",
    "    #Read in path file for training set and validation set\n",
    "    val_paths = pd.read_csv('/data/home/huixian/Documents/567/MURA-v1.1/valid_image_paths.csv',header=None,names=[\"path\"])\n",
    "    #create labels to classify normal and abnormal, first intiate all to be 0\n",
    "    val_paths['label']=0\n",
    "    #if find \"positive\" in path, set the label from 0 to 1\n",
    "    val_paths.loc[val_paths['path'].str.contains('positive'),'label']=1\n",
    "\n",
    "    #subset for body site images path\n",
    "    val_y = val_paths[val_paths['path'].str.contains(body_site)]\n",
    "\n",
    "    val_images = []\n",
    "    for path in val_y['path']:\n",
    "        img = load_img(path,target_size=image_size,color_mode=color_mode)\n",
    "        #img_arr = per_image_standardization(img_to_array(img))\n",
    "        img_arr = img_to_array(img)\n",
    "        img_arr = per_image_standardization(img_arr)\n",
    "        val_images.append(img_arr)\n",
    "    val_X = np.array(val_images)\n",
    "\n",
    "    val_y = val_y.set_index('path')\n",
    "\n",
    "    return val_X, val_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load all data as whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ALL_data(image_size, color_mode):\n",
    "    '''\n",
    "    Specify body site, image size, color mode above\n",
    "\n",
    "    '''\n",
    "    #Read in path file for training set and validation set\n",
    "    train_paths = pd.read_csv('/data/home/huixian/Documents/567/MURA-v1.1/train_image_paths.csv',  header=None,names=[\"path\"])\n",
    "    val_paths = pd.read_csv('/data/home/huixian/Documents/567/MURA-v1.1/valid_image_paths.csv',header=None,names=[\"path\"])\n",
    "    #create labels to classify normal and abnormal, first intiate all to be 0\n",
    "    train_paths['label']=0\n",
    "    val_paths['label']=0\n",
    "    #if find \"positive\" in path, set the label from 0 to 1\n",
    "    train_paths.loc[train_paths['path'].str.contains('positive'),'label']=1\n",
    "    val_paths.loc[val_paths['path'].str.contains('positive'),'label']=1\n",
    "\n",
    "    #subset for body site images path\n",
    "    train_y = train_paths[train_paths['path'].str.contains(\"M\")]\n",
    "    val_y = val_paths[val_paths['path'].str.contains(\"M\")]\n",
    "\n",
    "    #load training images as a 4 dimentional np array\n",
    "    train_images = []\n",
    "    for path in train_y['path']:\n",
    "        img = load_img(path,target_size=image_size,color_mode=color_mode)\n",
    "        #img_arr = per_image_standardization(img_to_array(img))\n",
    "        img_arr = img_to_array(img)\n",
    "        img_arr = per_image_standardization(img_arr)\n",
    "        train_images.append(img_arr)\n",
    "    train_X = np.array(train_images)\n",
    "    print(np.shape(train_X[0]))\n",
    "    #load validation images as a 4 dimentional np array\n",
    "    val_images = []\n",
    "    for path in val_y['path']:\n",
    "        img = load_img(path,target_size=image_size,color_mode=color_mode)\n",
    "        #img_arr = per_image_standardization(img_to_array(img))\n",
    "        img_arr = img_to_array(img)\n",
    "        img_arr = per_image_standardization(img_arr)\n",
    "        val_images.append(img_arr)\n",
    "    val_X = np.array(val_images)\n",
    "\n",
    "    #set path as index (in other words, drop path column) such that only contain labels\n",
    "    train_y = train_y.set_index('path')\n",
    "    val_y = val_y.set_index('path')\n",
    "\n",
    "    #calculate number of observations and percentage\n",
    "    train_count_all = len(train_y)\n",
    "    train_count_normal = sum(train_y['label']==0)\n",
    "    train_count_abnormal = sum(train_y['label']==1)\n",
    "    train_count_percentage = round(train_count_abnormal*100/train_count_all,2)\n",
    "    val_count_all = len (val_y)\n",
    "    val_count_normal = sum(val_y['label']==0)\n",
    "    val_count_abnormal = sum(val_y['label']==1)\n",
    "    val_count_percentage = round(val_count_abnormal*100/val_count_all,2)\n",
    "\n",
    "    #print relevant information\n",
    "    print(f'*********')\n",
    "    print(f'We are ALL {color_mode} images with {image_size[0]}*{image_size[1]} image size.')\n",
    "    print(f'The training set has a total of {train_count_all} images, of them, {train_count_normal} are normal and {train_count_abnormal} are abnormal images, the percentage of abnormal is {train_count_percentage}%.')\n",
    "    print(f'The validation set has a total of {val_count_all} images, of them, {val_count_normal} are normal and {val_count_abnormal} are abnormal images, the percentage of abnormal is {val_count_percentage}%.')\n",
    "    print(f'The training np array X has a dimentsion of {train_X.shape}')\n",
    "    print(f'The validation np array X has a dimentsion of {val_X.shape}')\n",
    "    print(f'The training label y has a dimentsion of {train_y.shape}')\n",
    "    print(f'The validation label y has a dimentsion of {val_y.shape}')\n",
    "    return train_X, train_y, val_X, val_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_site = \"FOREARM\"\n",
    "# body_site = \"ELBOW\"\n",
    "# body_site = \"HUMERUS\"\n",
    "# body_site = \"WRIST\"\n",
    "# body_site = \"HAND\"\n",
    "# body_site = \"FINGER\"\n",
    "# body_site = \"SHOULDER\"\n",
    "FOREARM_train_X, FOREARM_train_y, FOREARM_val_X, FOREARM_val_y = load_data(\"FOREARM\",image_size,color_mode)\n",
    "ELBOW_train_X, ELBOW_train_y, ELBOW_val_X, ELBOW_val_y = load_data(\"ELBOW\",image_size,color_mode)\n",
    "HUMERUS_train_X, HUMERUS_train_y, HUMERUS_val_X, HUMERUS_val_y = load_data(\"HUMERUS\",image_size,color_mode)\n",
    "WRIST_train_X, WRIST_train_y, WRIST_val_X, WRIST_val_y = load_data(\"WRIST\",image_size,color_mode)\n",
    "HAND_train_X, HAND_train_y, HAND_val_X, HAND_val_y = load_data(\"HAND\",image_size,color_mode)\n",
    "FINGER_train_X, FINGER_train_y, FINGER_val_X, FINGER_val_y = load_data(\"FINGER\",image_size,color_mode)\n",
    "SHOULDER_train_X, SHOULDER_train_y, SHOULDER_val_X, SHOULDER_val_y = load_data(\"SHOULDER\",image_size,color_mode)\n",
    "\n",
    "train_X, train_y, val_X, val_y = load_ALL_data(image_size,color_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734143872.800943 1269875 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46673 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "*********\n",
      "We are ALL rgb images with 224*224 image size.\n",
      "The training set has a total of 36808 images, of them, 21935 are normal and 14873 are abnormal images, the percentage of abnormal is 40.0%.\n",
      "The validation set has a total of 3197 images, of them, 1667 are normal and 1530 are abnormal images, the percentage of abnormal is 48.0%.\n",
      "The training np array X has a dimentsion of (36808, 224, 224, 3)\n",
      "The validation np array X has a dimentsion of (3197, 224, 224, 3)\n",
      "The training label y has a dimentsion of (36808, 1)\n",
      "The validation label y has a dimentsion of (3197, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, val_X, val_y = load_ALL_data(image_size,color_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mask_images(imgs,mask_size,maskn):\n",
    "\n",
    "    imgs2 = []\n",
    "    if mask_size==0 or maskn==0:\n",
    "        return imgs\n",
    "    else:\n",
    "        num_masks = math.floor(float(imgs[0].shape[0])/mask_size)\n",
    "        for img in imgs:\n",
    "            xy = random.sample([(x,y) for x in range(num_masks) for y in range(num_masks)],k=maskn)\n",
    "            img2 = img.copy()\n",
    "            for x,y in xy:\n",
    "                img2[(x*mask_size):((x+1)*mask_size),(y*mask_size):((y+1)*mask_size),:] = 0.0\n",
    "            imgs2.append(img2)\n",
    "        return np.array(imgs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Cohen Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class CohenKappa(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='cohen_kappa', num_classes=2, **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        # Initialize the confusion matrix as a variable\n",
    "        self.conf_mat = self.add_weight(\n",
    "            name='conf_mat',\n",
    "            shape=(num_classes, num_classes),\n",
    "            initializer='zeros',\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert probabilities to binary predictions (threshold at 0.5)\n",
    "        y_pred = tf.cast(y_pred > 0.5, tf.int32)\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "\n",
    "        # Reshape to ensure they are 1D\n",
    "        y_true = tf.reshape(y_true, [-1])\n",
    "        y_pred = tf.reshape(y_pred, [-1])\n",
    "\n",
    "        # Compute the confusion matrix for this batch\n",
    "        batch_conf_mat = tf.math.confusion_matrix(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            num_classes=self.num_classes,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # Accumulate the confusion matrix counts\n",
    "        return self.conf_mat.assign_add(batch_conf_mat)\n",
    "\n",
    "    def result(self):\n",
    "        # Compute Cohen's kappa from the confusion matrix\n",
    "        mat = self.conf_mat\n",
    "        total = tf.reduce_sum(mat)\n",
    "        # Observed Accuracy\n",
    "        observed = tf.reduce_sum(tf.linalg.diag_part(mat)) / total\n",
    "\n",
    "        # Calculate expected accuracy\n",
    "        sum_rows = tf.reduce_sum(mat, axis=1)\n",
    "        sum_cols = tf.reduce_sum(mat, axis=0)\n",
    "        expected = tf.reduce_sum(sum_rows * sum_cols) / (total * total)\n",
    "\n",
    "        # Cohen's kappa\n",
    "        kappa = (observed - expected) / (1.0 - expected)\n",
    "        return kappa\n",
    "\n",
    "    def reset_states(self):\n",
    "        # Reset the confusion matrix to zeros\n",
    "        tf.keras.backend.set_value(\n",
    "            self.conf_mat, \n",
    "            np.zeros((self.num_classes, self.num_classes), dtype=np.float32)\n",
    "        )\n",
    "\n",
    "# Example usage in a model:\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "#               metrics=['accuracy', tf.keras.metrics.AUC(name='auc'), CohenKappa()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Fix the seed\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "image_shape = (224,224,1)\n",
    "\n",
    "base_model = CustomizeDenseNet(weights='imagenet', input_shape=image_shape)\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)  # Reduced size of the layer\n",
    "x = layers.Dropout(0.1)(x)                   # Slightly higher dropout to combat overfitting\n",
    "\n",
    "# Final classification layer\n",
    "predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy',AUC(),CohenKappa()])\n",
    "\n",
    "original_datagen = tf.keras.preprocessing.image.ImageDataGenerator()  # No augmentation\n",
    "original_gen = original_datagen.flow(train_X, train_y, batch_size=64, shuffle=True)\n",
    "results_pre=model.fit(original_gen,validation_data=(val_X, val_y),steps_per_epoch=original_gen.n//original_gen.batch_size,validation_batch_size=64,epochs=100,verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## additional trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/data/home/huixian/Documents/567/muramodel_weights_1e-6.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/data/home/huixian/Documents/567/training_log/muramodel_weights_1e-6.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range = 30, horizontal_flip = True)\n",
    "\n",
    "traingen = datagen.flow(train_X, train_y, batch_size = 64, shuffle = True)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-6), loss='binary_crossentropy', metrics=['accuracy',AUC(),CohenKappa()])\n",
    "\n",
    "results_pre=model.fit(traingen,validation_data=(val_X, val_y),steps_per_epoch=original_gen.n//original_gen.batch_size,validation_batch_size=64,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range = 45, horizontal_flip = True)\n",
    "\n",
    "traingen = datagen.flow(SHOULDER_train_X, SHOULDER_train_y, batch_size = 64, shuffle = True)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-6), loss='binary_crossentropy', metrics=['accuracy',AUC(),CohenKappa()])\n",
    "\n",
    "results_pre=model.fit(traingen,validation_data=(SHOULDER_val_X, SHOULDER_val_y),steps_per_epoch=original_gen.n//original_gen.batch_size,validation_batch_size=64,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pre=model.fit(traingen,validation_data=(FINGER_val_X, FINGER_val_y),steps_per_epoch=original_gen.n//original_gen.batch_size,validation_batch_size=64,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range = 45, horizontal_flip = True)\n",
    "\n",
    "traingen = datagen.flow(FINGER_train_X, FINGER_train_y, batch_size = 64, shuffle = True)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-7), loss='binary_crossentropy', metrics=['accuracy',AUC(),CohenKappa()])\n",
    "\n",
    "results_pre=model.fit(traingen,validation_data=(FINGER_val_X, FINGER_val_y),steps_per_epoch=original_gen.n//original_gen.batch_size,validation_batch_size=64,epochs=50,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoostedNet Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "class BoostedDenseNet:\n",
    "    def __init__(self, n_estimators=5, learning_rate=0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.models = []\n",
    "        self.weights = None\n",
    "        \n",
    "    def create_model(self, input_shape, weights = 'xx'):\n",
    "        \"\"\"Creates a single DenseNet model with the same architecture\"\"\"\n",
    "        base_model = CustomizeDenseNet(input_shape=input_shape, weights = weights)\n",
    "        x = base_model.output\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dense(1024, activation='relu')(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        # model.load_weights('/data/home/huixian/Documents/567/training_log/muramodel_weights.weights.h5')\n",
    "        model.compile(optimizer=optimizers.Adam(learning_rate=1e-6),\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['accuracy', AUC(), CohenKappa()])\n",
    "        return model\n",
    "        \n",
    "    def fit(self, X, y, validation_data=None, epochs=10):\n",
    "        \"\"\"Fits multiple DenseNet models using boosting\"\"\"\n",
    "        n_samples = len(X)\n",
    "        self.weights = np.ones(n_samples) / n_samples\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            print(f\"Training model {i+1}/{self.n_estimators}\")\n",
    "            \n",
    "            # Create and train a new model\n",
    "            model = self.create_model(input_shape=X.shape[1:])\n",
    "            \n",
    "            # Create weighted dataset\n",
    "            sample_weights = self.weights * n_samples\n",
    "            \n",
    "            # Train the model\n",
    "            datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=45,\n",
    "                horizontal_flip=True\n",
    "            )\n",
    "            \n",
    "            traingen = datagen.flow(\n",
    "                X, y,\n",
    "                sample_weight=sample_weights,\n",
    "                batch_size=64,\n",
    "                shuffle=True\n",
    "            )\n",
    "            \n",
    "            model.fit(\n",
    "                traingen,\n",
    "                validation_data=validation_data,\n",
    "                steps_per_epoch=len(X)//64,\n",
    "                epochs=epochs,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # Make predictions\n",
    "            predictions = (model.predict(X) > 0.5).astype(int)\n",
    "            \n",
    "            # Calculate error and model weight\n",
    "            incorrect = (predictions.flatten() != y.flatten())\n",
    "            error = np.sum(self.weights * incorrect) / np.sum(self.weights)\n",
    "            \n",
    "            # Avoid division by zero and log(0)\n",
    "            error = np.clip(error, 1e-10, 1-1e-10)\n",
    "            model_weight = self.learning_rate * np.log((1 - error) / error)\n",
    "            \n",
    "            # Update sample weights\n",
    "            self.weights *= np.exp(model_weight * incorrect)\n",
    "            self.weights /= np.sum(self.weights)  # Normalize weights\n",
    "            \n",
    "            # Save the model and its weight\n",
    "            self.models.append((model, model_weight))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"Makes predictions using weighted voting of all models\"\"\"\n",
    "        predictions = np.zeros(len(X))\n",
    "        total_weight = 0\n",
    "        \n",
    "        for model, model_weight in self.models:\n",
    "            predictions += model_weight * model.predict(X).flatten()\n",
    "            total_weight += model_weight\n",
    "            \n",
    "        predictions /= total_weight\n",
    "        return (predictions > 0.5).astype(int)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Returns probability predictions\"\"\"\n",
    "        predictions = np.zeros(len(X))\n",
    "        total_weight = 0\n",
    "        \n",
    "        for model, model_weight in self.models:\n",
    "            predictions += model_weight * model.predict(X).flatten()\n",
    "            total_weight += model_weight\n",
    "            \n",
    "        return predictions / total_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoostedNet Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import tensorflow as tf \n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def train_boosted_model(train_X, train_y, val_X, val_y, \n",
    "                       n_estimators=3, \n",
    "                       learning_rate=0.1,\n",
    "                       epochs_per_model=10,\n",
    "                       save_prefix=\"boosted_model\"):\n",
    "    \"\"\"\n",
    "    Train a boosted DenseNet model and save results\n",
    "    \"\"\"\n",
    "    # Initialize model\n",
    "    print(\"Initializing boosted model...\")\n",
    "    boosted_model = BoostedDenseNet(n_estimators=n_estimators, \n",
    "                                   learning_rate=learning_rate)\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"Starting training with {n_estimators} estimators...\")\n",
    "    history = boosted_model.fit(\n",
    "        train_X, \n",
    "        train_y,\n",
    "        validation_data=(val_X, val_y),\n",
    "        epochs=epochs_per_model\n",
    "    )\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"Generating predictions...\")\n",
    "    val_preds = boosted_model.predict(val_X)\n",
    "    val_probs = boosted_model.predict_proba(val_X)\n",
    "\n",
    "    # Calculate metrics\n",
    "    print(\"Calculating metrics...\")\n",
    "    metrics = {\n",
    "        'auc': roc_auc_score(val_y, val_probs),\n",
    "        'kappa': cohen_kappa_score(val_y, val_preds),\n",
    "        'conf_matrix': confusion_matrix(val_y, val_preds)\n",
    "    }\n",
    "    \n",
    "    # Save results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'timestamp': [timestamp],\n",
    "        'n_estimators': [n_estimators],\n",
    "        'learning_rate': [learning_rate],\n",
    "        'epochs_per_model': [epochs_per_model],\n",
    "        'training_time': [training_time],\n",
    "        'auc': [metrics['auc']],\n",
    "        'kappa': [metrics['kappa']],\n",
    "        'tn': [metrics['conf_matrix'][0,0]],\n",
    "        'fp': [metrics['conf_matrix'][0,1]],\n",
    "        'fn': [metrics['conf_matrix'][1,0]],\n",
    "        'tp': [metrics['conf_matrix'][1,1]]\n",
    "    })\n",
    "    \n",
    "    metrics_file = f\"{save_prefix}_metrics_{timestamp}.csv\"\n",
    "    metrics_df.to_csv(metrics_file, index=False)\n",
    "    print(f\"Saved metrics to {metrics_file}\")\n",
    "    \n",
    "    # Save ROC curve data\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, _ = roc_curve(val_y, val_probs)\n",
    "    roc_df = pd.DataFrame({\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr\n",
    "    })\n",
    "    \n",
    "    roc_file = f\"{save_prefix}_roc_{timestamp}.csv\"\n",
    "    roc_df.to_csv(roc_file, index=False)\n",
    "    print(f\"Saved ROC curve data to {roc_file}\")\n",
    "    \n",
    "    # Save individual model weights\n",
    "    for i, (model, weight) in enumerate(boosted_model.models):\n",
    "        weight_file = f\"{save_prefix}_model{i+1}_{timestamp}.weights.h5\"\n",
    "        model.save_weights(weight_file)\n",
    "        print(f\"Saved weights for model {i+1} to {weight_file}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nTraining Summary:\")\n",
    "    print(f\"Number of estimators: {n_estimators}\")\n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Epochs per model: {epochs_per_model}\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"Validation AUC: {metrics['auc']:.4f}\")\n",
    "    print(f\"Validation Kappa: {metrics['kappa']:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(metrics['conf_matrix'])\n",
    "    \n",
    "    return boosted_model, metrics\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating metrics...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m: roc_auc_score(val_y, \u001b[43mval_probs\u001b[49m),\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkappa\u001b[39m\u001b[38;5;124m'\u001b[39m: cohen_kappa_score(val_y, val_preds),\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconf_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m: confusion_matrix(val_y, val_preds)\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[1;32m     17\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_probs' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "print(\"Calculating metrics...\")\n",
    "metrics = {\n",
    "    'auc': roc_auc_score(val_y, val_probs),\n",
    "    'kappa': cohen_kappa_score(val_y, val_preds),\n",
    "    'conf_matrix': confusion_matrix(val_y, val_preds)\n",
    "}\n",
    "\n",
    "# Save results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'timestamp': [timestamp],\n",
    "    'n_estimators': [n_estimators],\n",
    "    'learning_rate': [learning_rate],\n",
    "    'epochs_per_model': [epochs_per_model],\n",
    "    'training_time': [training_time],\n",
    "    'auc': [metrics['auc']],\n",
    "    'kappa': [metrics['kappa']],\n",
    "    'tn': [metrics['conf_matrix'][0,0]],\n",
    "    'fp': [metrics['conf_matrix'][0,1]],\n",
    "    'fn': [metrics['conf_matrix'][1,0]],\n",
    "    'tp': [metrics['conf_matrix'][1,1]]\n",
    "})\n",
    "\n",
    "metrics_file = f\"{save_prefix}_metrics_{timestamp}.csv\"\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"Saved metrics to {metrics_file}\")\n",
    "\n",
    "# Save ROC curve data\n",
    "fpr, tpr, _ = roc_curve(val_y, val_probs)\n",
    "roc_df = pd.DataFrame({\n",
    "    'fpr': fpr,\n",
    "    'tpr': tpr\n",
    "})\n",
    "\n",
    "roc_file = f\"{save_prefix}_roc_{timestamp}.csv\"\n",
    "roc_df.to_csv(roc_file, index=False)\n",
    "print(f\"Saved ROC curve data to {roc_file}\")\n",
    "\n",
    "# Save individual model weights\n",
    "for i, (model, weight) in enumerate(boosted_model.models):\n",
    "    weight_file = f\"{save_prefix}_model{i+1}_{timestamp}.weights.h5\"\n",
    "    model.save_weights(weight_file)\n",
    "    print(f\"Saved weights for model {i+1} to {weight_file}\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"Number of estimators: {n_estimators}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Epochs per model: {epochs_per_model}\")\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "print(f\"Validation AUC: {metrics['auc']:.4f}\")\n",
    "print(f\"Validation Kappa: {metrics['kappa']:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics['conf_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "image_shape=(224,224,3)\n",
    "def train_boosted_model(train_X, train_y, val_X, val_y, \n",
    "                       n_estimators=3,\n",
    "                       learning_rate=0.1,\n",
    "                       epochs_per_model=10,\n",
    "                       save_prefix=\"boosted_model\"):\n",
    "    \"\"\"Train a boosted DenseNet model and save results\"\"\"\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"Initializing boosted model...\")\n",
    "    boosted_model = BoostedDenseNet(n_estimators=n_estimators, \n",
    "                                   learning_rate=learning_rate)\n",
    "    \n",
    "    # Initialize sample weights\n",
    "    n_samples = len(train_X)\n",
    "    boosted_model.weights = np.ones(n_samples) / n_samples\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train all models\n",
    "    for i in range(n_estimators):\n",
    "        print(f\"\\nTraining model {i+1}/{n_estimators}\")\n",
    "        \n",
    "        # Create new model with ImageNet weights\n",
    "        model = boosted_model.create_model(input_shape=(224,224,3), weights = 'imagenet')\n",
    "        \n",
    "        # Create weighted dataset\n",
    "        sample_weights = boosted_model.weights * n_samples\n",
    "        \n",
    "        # Setup data generator without augmentation\n",
    "        datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "        traingen = datagen.flow(\n",
    "            train_X, train_y,\n",
    "            sample_weight=sample_weights,\n",
    "            batch_size=64,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(\n",
    "            traingen,\n",
    "            validation_data=(val_X, val_y),\n",
    "            steps_per_epoch=len(train_X)//64,\n",
    "            epochs=epochs_per_model,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Calculate error and model weight\n",
    "        predictions = (model.predict(train_X) > 0.5).astype(int)\n",
    "        incorrect = (predictions.flatten() != train_y.flatten())\n",
    "        error = np.sum(boosted_model.weights * incorrect) / np.sum(boosted_model.weights)\n",
    "        error = np.clip(error, 1e-10, 1-1e-10)\n",
    "        model_weight = learning_rate * np.log((1 - error) / error)\n",
    "        \n",
    "        # Add model to ensemble\n",
    "        boosted_model.models.append((model, model_weight))\n",
    "        \n",
    "        # Update sample weights for next iteration\n",
    "        if i < n_estimators - 1:\n",
    "            boosted_model.weights *= np.exp(model_weight * incorrect)\n",
    "            boosted_model.weights /= np.sum(boosted_model.weights)\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "    # timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Save individual model weights\n",
    "    for i, (model, weight) in enumerate(boosted_model.models):\n",
    "        weight_file = f\"{save_prefix}_model{i+1}_final.weights.h5\"\n",
    "        model.save_weights(weight_file)\n",
    "        print(f\"Saved weights for model {i+1} to {weight_file}\")\n",
    "   \n",
    "    return boosted_model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoostedNet Train/Load code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Starting boosted model training...\n",
      "Initializing boosted model...\n",
      "\n",
      "Training model 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/huixian/.conda/envs/scratch/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m314/575\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 109ms/step - accuracy: 0.5714 - auc_23: 0.5366 - cohen_kappa: 0.0456 - loss: 0.7095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 23:18:48.345023: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'loop_slice_fusion_57', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_3', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_72', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_74', 20 bytes spill stores, 20 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_compare_reduce_fusion_31', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_compare_reduce_fusion_32', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_compare_reduce_fusion_33', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_269', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_272', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_273', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 350ms/step - accuracy: 0.5879 - auc_23: 0.5674 - cohen_kappa: 0.0837 - loss: 0.6920 - val_accuracy: 0.6143 - val_auc_23: 0.6874 - val_cohen_kappa: 0.2088 - val_loss: 0.6699\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/575\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 153ms/step - accuracy: 0.6719 - auc_23: 0.7896 - cohen_kappa: 0.3438 - loss: 0.5952"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/huixian/.conda/envs/scratch/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6719 - auc_23: 0.7896 - cohen_kappa: 0.3438 - loss: 0.5952 - val_accuracy: 0.6150 - val_auc_23: 0.6873 - val_cohen_kappa: 0.2102 - val_loss: 0.6696\n",
      "Epoch 3/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 116ms/step - accuracy: 0.6868 - auc_23: 0.7280 - cohen_kappa: 0.3186 - loss: 0.5917 - val_accuracy: 0.6828 - val_auc_23: 0.7486 - val_cohen_kappa: 0.3555 - val_loss: 0.6050\n",
      "Epoch 4/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7656 - auc_23: 0.7391 - cohen_kappa: 0.4861 - loss: 0.5790 - val_accuracy: 0.6831 - val_auc_23: 0.7488 - val_cohen_kappa: 0.3561 - val_loss: 0.6048\n",
      "Epoch 5/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 118ms/step - accuracy: 0.7302 - auc_23: 0.7799 - cohen_kappa: 0.4167 - loss: 0.5478 - val_accuracy: 0.7082 - val_auc_23: 0.7788 - val_cohen_kappa: 0.4075 - val_loss: 0.5762\n",
      "Epoch 6/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7188 - auc_23: 0.7991 - cohen_kappa: 0.4194 - loss: 0.5364 - val_accuracy: 0.7082 - val_auc_23: 0.7788 - val_cohen_kappa: 0.4075 - val_loss: 0.5760\n",
      "Epoch 7/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 118ms/step - accuracy: 0.7549 - auc_23: 0.8170 - cohen_kappa: 0.4754 - loss: 0.5108 - val_accuracy: 0.7241 - val_auc_23: 0.7971 - val_cohen_kappa: 0.4407 - val_loss: 0.5541\n",
      "Epoch 8/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7656 - auc_23: 0.8517 - cohen_kappa: 0.5219 - loss: 0.4692 - val_accuracy: 0.7241 - val_auc_23: 0.7971 - val_cohen_kappa: 0.4407 - val_loss: 0.5539\n",
      "Epoch 9/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 119ms/step - accuracy: 0.7733 - auc_23: 0.8360 - cohen_kappa: 0.5141 - loss: 0.4867 - val_accuracy: 0.7348 - val_auc_23: 0.8115 - val_cohen_kappa: 0.4631 - val_loss: 0.5333\n",
      "Epoch 10/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8281 - auc_23: 0.8892 - cohen_kappa: 0.6157 - loss: 0.4367 - val_accuracy: 0.7338 - val_auc_23: 0.8115 - val_cohen_kappa: 0.4612 - val_loss: 0.5334\n",
      "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step\n",
      "\n",
      "Training model 2/5\n",
      "Epoch 1/10\n",
      "\u001b[1m159/575\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 106ms/step - accuracy: 0.5114 - auc_24: 0.5282 - cohen_kappa: 0.0437 - loss: 0.7463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 23:30:57.511555: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'loop_slice_fusion_57', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_3', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_72', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_74', 20 bytes spill stores, 20 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_compare_reduce_fusion_31', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_compare_reduce_fusion_32', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_compare_reduce_fusion_33', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_269', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_272', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_273', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 358ms/step - accuracy: 0.5518 - auc_24: 0.5813 - cohen_kappa: 0.1116 - loss: 0.7087 - val_accuracy: 0.6406 - val_auc_24: 0.6892 - val_cohen_kappa: 0.2755 - val_loss: 0.6388\n",
      "Epoch 2/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7500 - auc_24: 0.7975 - cohen_kappa: 0.4834 - loss: 0.5895 - val_accuracy: 0.6406 - val_auc_24: 0.6893 - val_cohen_kappa: 0.2755 - val_loss: 0.6386\n",
      "Epoch 3/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 116ms/step - accuracy: 0.6735 - auc_24: 0.7235 - cohen_kappa: 0.3202 - loss: 0.6000 - val_accuracy: 0.6819 - val_auc_24: 0.7431 - val_cohen_kappa: 0.3569 - val_loss: 0.6000\n",
      "Epoch 4/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7812 - auc_24: 0.7508 - cohen_kappa: 0.5061 - loss: 0.5799 - val_accuracy: 0.6831 - val_auc_24: 0.7430 - val_cohen_kappa: 0.3595 - val_loss: 0.5999\n",
      "Epoch 5/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 117ms/step - accuracy: 0.7215 - auc_24: 0.7764 - cohen_kappa: 0.4090 - loss: 0.5519 - val_accuracy: 0.7141 - val_auc_24: 0.7755 - val_cohen_kappa: 0.4216 - val_loss: 0.5707\n",
      "Epoch 6/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7188 - auc_24: 0.7932 - cohen_kappa: 0.3793 - loss: 0.5140 - val_accuracy: 0.7138 - val_auc_24: 0.7754 - val_cohen_kappa: 0.4210 - val_loss: 0.5706\n",
      "Epoch 7/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 119ms/step - accuracy: 0.7511 - auc_24: 0.8090 - cohen_kappa: 0.4704 - loss: 0.5187 - val_accuracy: 0.7307 - val_auc_24: 0.7947 - val_cohen_kappa: 0.4549 - val_loss: 0.5537\n",
      "Epoch 8/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7031 - auc_24: 0.8125 - cohen_kappa: 0.3796 - loss: 0.5086 - val_accuracy: 0.7304 - val_auc_24: 0.7948 - val_cohen_kappa: 0.4543 - val_loss: 0.5537\n",
      "Epoch 9/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 115ms/step - accuracy: 0.7718 - auc_24: 0.8338 - cohen_kappa: 0.5149 - loss: 0.4894 - val_accuracy: 0.7391 - val_auc_24: 0.8082 - val_cohen_kappa: 0.4721 - val_loss: 0.5375\n",
      "Epoch 10/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6875 - auc_24: 0.8583 - cohen_kappa: 0.3870 - loss: 0.5157 - val_accuracy: 0.7388 - val_auc_24: 0.8082 - val_cohen_kappa: 0.4715 - val_loss: 0.5376\n",
      "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 29ms/step\n",
      "\n",
      "Training model 3/5\n",
      "Epoch 1/10\n",
      "\u001b[1m527/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - accuracy: 0.5881 - auc_25: 0.5902 - cohen_kappa: 0.1100 - loss: 0.6761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 23:43:19.603255: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'loop_slice_fusion_57', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_3', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_72', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_74', 20 bytes spill stores, 20 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_compare_reduce_fusion_31', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_compare_reduce_fusion_32', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_compare_reduce_fusion_33', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_269', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_272', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_273', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 352ms/step - accuracy: 0.5908 - auc_25: 0.5944 - cohen_kappa: 0.1161 - loss: 0.6739 - val_accuracy: 0.6234 - val_auc_25: 0.7015 - val_cohen_kappa: 0.2303 - val_loss: 0.6497\n",
      "Epoch 2/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6719 - auc_25: 0.6872 - cohen_kappa: 0.2956 - loss: 0.6382 - val_accuracy: 0.6234 - val_auc_25: 0.7016 - val_cohen_kappa: 0.2303 - val_loss: 0.6495\n",
      "Epoch 3/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 116ms/step - accuracy: 0.6924 - auc_25: 0.7364 - cohen_kappa: 0.3374 - loss: 0.5861 - val_accuracy: 0.6869 - val_auc_25: 0.7613 - val_cohen_kappa: 0.3643 - val_loss: 0.5912\n",
      "Epoch 4/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7969 - auc_25: 0.8098 - cohen_kappa: 0.5772 - loss: 0.5279 - val_accuracy: 0.6863 - val_auc_25: 0.7615 - val_cohen_kappa: 0.3631 - val_loss: 0.5909\n",
      "Epoch 5/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 109ms/step - accuracy: 0.7298 - auc_25: 0.7867 - cohen_kappa: 0.4186 - loss: 0.5422 - val_accuracy: 0.7094 - val_auc_25: 0.7924 - val_cohen_kappa: 0.4107 - val_loss: 0.5598\n",
      "Epoch 6/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7188 - auc_25: 0.8581 - cohen_kappa: 0.4098 - loss: 0.5064 - val_accuracy: 0.7107 - val_auc_25: 0.7924 - val_cohen_kappa: 0.4132 - val_loss: 0.5597\n",
      "Epoch 7/10\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 114ms/step - accuracy: 0.7537 - auc_25: 0.8148 - cohen_kappa: 0.4731 - loss: 0.5138 - val_accuracy: 0.7279 - val_auc_25: 0.8110 - val_cohen_kappa: 0.4485 - val_loss: 0.5379\n",
      "Epoch 8/10\n",
      "\u001b[1m  1/575\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 117ms/step - accuracy: 0.7500 - auc_25: 0.8402 - cohen_kappa: 0.4880 - loss: 0.4967"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Training parameters\n",
    "PARAMS = {\n",
    "    'n_estimators': 5,\n",
    "    'learning_rate': 1e-6,\n",
    "    'epochs_per_model': 10\n",
    "}\n",
    "\n",
    "# Load and preprocess data\n",
    "print(\"Loading data...\")\n",
    "image_size = (224, 224)\n",
    "color_mode = \"rgb\"\n",
    "\n",
    "# Train on all body sites\n",
    "# train_X, train_y, val_X, val_y = load_ALL_data(image_size, color_mode)\n",
    "\n",
    "# Train model\n",
    "print(\"\\nStarting boosted model training...\")\n",
    "boosted_model, metrics = train_boosted_model(\n",
    "    train_X, train_y['label'].values, \n",
    "    val_X, val_y['label'].values,\n",
    "    **PARAMS,\n",
    "    save_prefix=\"densenet_boosted_rgb\"\n",
    ")\n",
    "\n",
    "# def load_boosted_model_weights(timestamp, n_estimators=5, learning_rate=1e-6):\n",
    "#     \"\"\"\n",
    "#     Load weights for all models in the boosted ensemble\n",
    "#     \"\"\"\n",
    "#     # Initialize a new BoostedDenseNet instance\n",
    "#     boosted_model = BoostedDenseNet(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "#     boosted_model.models = []\n",
    "    \n",
    "#     for i in range(n_estimators):\n",
    "#         # Create a new model using the create_model method from BoostedDenseNet\n",
    "#         model = boosted_model.create_model(input_shape=(224,224,1))\n",
    "        \n",
    "#         # Load the saved weights\n",
    "#         weight_file = f\"densenet_boosted_model{i+1}_{timestamp}.weights.h5\"\n",
    "#         model.load_weights(weight_file)\n",
    "        \n",
    "#         # For now, use equal weights for all models since we don't save the model weights\n",
    "#         # You might want to save and load these weights separately in your training code\n",
    "#         model_weight = 1.0 / n_estimators\n",
    "        \n",
    "#         # Add to models list as tuple of (model, weight)\n",
    "#         boosted_model.models.append((model, model_weight))\n",
    "#         print(f\"Loaded weights for model {i+1} from {weight_file}\")\n",
    "    \n",
    "#     return boosted_model\n",
    "\n",
    "# timestamp = \"20241211_174317\"\n",
    "# boosted_model = load_boosted_model_weights(\n",
    "#     timestamp=timestamp, \n",
    "#     n_estimators=5,\n",
    "#     learning_rate=1e-6\n",
    "# )\n",
    "# Example usage:\n",
    "# timestamp = \"20241211_174317\"  # Replace with your actual timestamp\n",
    "# boosted_model = load_boosted_model_weights(timestamp, n_estimators=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoostedNet Eval Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Evaluate on individual body sites\n",
    "if True:  # Set to True to evaluate on individual sites\n",
    "    print(\"\\nEvaluating on individual body sites...\")\n",
    "    site_metrics = []\n",
    "    \n",
    "    for site in [\"WRIST\", \"SHOULDER\", \"HUMERUS\", \"HAND\", \"FOREARM\", \"FINGER\", \"ELBOW\"]:\n",
    "        print(f\"\\nEvaluating {site}...\")\n",
    "        site_val_X, site_val_y = load_val_data(site, image_size, color_mode)\n",
    "        \n",
    "        # Get predictions\n",
    "        site_preds = boosted_model.predict(site_val_X)\n",
    "        site_probs = boosted_model.predict_proba(site_val_X)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        site_metrics.append({\n",
    "            'site': site,\n",
    "            'auc': roc_auc_score(site_val_y['label'], site_probs),\n",
    "            'kappa': cohen_kappa_score(site_val_y['label'], site_preds)\n",
    "        })\n",
    "    \n",
    "    # Save site-specific metrics\n",
    "    site_metrics_df = pd.DataFrame(site_metrics)\n",
    "    site_metrics_file = f\"densenet_boosted_site_metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    site_metrics_df.to_csv(site_metrics_file, index=False)\n",
    "    print(f\"\\nSaved site-specific metrics to {site_metrics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Eval Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "def evaluate_sites(model, image_size=(224,224), color_mode=\"rgb\"):\n",
    "    \"\"\"\n",
    "    Evaluate model performance on individual body sites\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluating on individual body sites...\")\n",
    "    site_metrics = []\n",
    "    \n",
    "    # Save ROC curve data for each site\n",
    "    roc_curves = {}\n",
    "    \n",
    "    for site in [\"WRIST\", \"SHOULDER\", \"HUMERUS\", \"HAND\", \"FOREARM\", \"FINGER\", \"ELBOW\"]:\n",
    "        print(f\"\\nEvaluating {site}...\")\n",
    "        site_val_X, site_val_y = load_val_data(site, image_size, color_mode)\n",
    "        \n",
    "        # Get predictions\n",
    "        site_probs = model.predict(site_val_X)\n",
    "        site_preds = (site_probs > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        conf_matrix = confusion_matrix(site_val_y, site_preds)\n",
    "        \n",
    "        site_metrics.append({\n",
    "            'site': site,\n",
    "            'auc': roc_auc_score(site_val_y, site_probs),\n",
    "            'kappa': cohen_kappa_score(site_val_y, site_preds),\n",
    "            'accuracy': accuracy_score(site_val_y, site_preds),\n",
    "            'tn': conf_matrix[0,0],\n",
    "            'fp': conf_matrix[0,1],\n",
    "            'fn': conf_matrix[1,0],\n",
    "            'tp': conf_matrix[1,1]\n",
    "        })\n",
    "        \n",
    "        # Calculate ROC curve\n",
    "        fpr, tpr, _ = roc_curve(site_val_y, site_probs)\n",
    "        roc_curves[site] = {'fpr': fpr, 'tpr': tpr}\n",
    "    \n",
    "    # Save metrics\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save site-specific metrics\n",
    "    site_metrics_df = pd.DataFrame(site_metrics)\n",
    "    site_metrics_file = f\"densenet_site_metrics_{timestamp}.csv\"\n",
    "    site_metrics_df.to_csv(site_metrics_file, index=False)\n",
    "    print(f\"\\nSaved site-specific metrics to {site_metrics_file}\")\n",
    "    \n",
    "    # Save ROC curves for each site\n",
    "    for site, curve_data in roc_curves.items():\n",
    "        roc_df = pd.DataFrame({\n",
    "            'fpr': curve_data['fpr'],\n",
    "            'tpr': curve_data['tpr']\n",
    "        })\n",
    "        roc_file = f\"densenet_roc_{site}_{timestamp}.csv\"\n",
    "        roc_df.to_csv(roc_file, index=False)\n",
    "        print(f\"Saved ROC curve data for {site} to {roc_file}\")\n",
    "        \n",
    "    # Print summary\n",
    "    print(\"\\nSite-specific Results:\")\n",
    "    print(site_metrics_df.to_string(index=False))\n",
    "    \n",
    "    return site_metrics_df, roc_curves\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Fix the seed\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "image_shape = (224,224,3)\n",
    "\n",
    "base_model = CustomizeDenseNet(weights='imagenet', input_shape=image_shape)\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "# x = layers.Flatten()(x)        # Normalize the features\n",
    "\n",
    "# A single or at most two Dense layers should usually suffice\n",
    "# x = layers.Dense(1024, activation='relu')(x)  # Reduced size of the layer\n",
    "# x = layers.Dropout(0.2)(x)                   # Slightly higher dropout to combat \n",
    "x = layers.Dense(1024, activation='relu')(x)  # Reduced size of the layer\n",
    "x = layers.Dropout(0.1)(x)                   # Slightly higher dropout to combat overfitting\n",
    "\n",
    "# Final classification layer\n",
    "predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# Train your model first\n",
    "# model.compile(optimizer=optimizers.Adam(learning_rate=1e-6), \n",
    "#              loss='binary_crossentropy', \n",
    "#              metrics=['accuracy', AUC(), CohenKappa()])\n",
    "\n",
    "# Training code here...\n",
    "\n",
    "# After training, evaluate on individual sites\n",
    "# site_metrics, roc_curves = evaluate_sites(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradcam Save Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_gradcam_n(20,0.5,FOREARM_train_y.index[FOREARM_train_y['label']==1].to_numpy(),FOREARM_train_X[np.where(FOREARM_train_y[\"label\"] == 1)[0]],model,find_target_layer(model),\"DN169_train_pos\", site = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_X_list = [FOREARM_train_X, ELBOW_train_X, HUMERUS_train_X, WRIST_train_X, HAND_train_X, FINGER_train_X, SHOULDER_train_X]\n",
    "train_y_list = [FOREARM_train_y, ELBOW_train_y, HUMERUS_train_y, WRIST_train_y, HAND_train_y, FINGER_train_y, SHOULDER_train_y]\n",
    "val_X_list = [FOREARM_val_X, ELBOW_val_X, HUMERUS_val_X, WRIST_val_X, HAND_val_X, FINGER_val_X, SHOULDER_val_X]\n",
    "val_y_list = [FOREARM_val_y, ELBOW_val_y, HUMERUS_val_y, WRIST_val_y, HAND_val_y, FINGER_val_y, SHOULDER_val_y]\n",
    "sites = [\"FOREARM\", \"ELBOW\", \"HUMERUS\", \"WRIST\", \"HAND\", \"FINGER\", \"SHOULDER\"]\n",
    "\n",
    "for i in tqdm(range(len(train_X_list))):\n",
    "    gray_save_gradcam_n(20,0.5,train_y_list[i].index[train_y_list[i]['label']==1].to_numpy(),train_X_list[i][np.where(train_y_list[i][\"label\"] == 1)[0]],boosted_model,gray_find_target_layer(boosted_model),\"DN169_train_pos\", site = sites[i])\n",
    "    gray_save_gradcam_n(20,0.5,train_y_list[i].index[train_y_list[i]['label']==0].to_numpy(),train_X_list[i][np.where(train_y_list[i][\"label\"] == 0)[0]],boosted_model,gray_find_target_layer(boosted_model),\"DN169_train_neg\", site = sites[i])\n",
    "    gray_save_gradcam_n(20,0.5,val_y_list[i].index[val_y_list[i]['label']==1].to_numpy(),val_X_list[i][np.where(val_y_list[i][\"label\"] == 1)[0]],boosted_model,gray_find_target_layer(boosted_model),\"DN169_val_pos\", site = sites[i])\n",
    "    gray_save_gradcam_n(20,0.5,val_y_list[i].index[val_y_list[i]['label']==0].to_numpy(),val_X_list[i][np.where(val_y_list[i][\"label\"] == 0)[0]],boosted_model,gray_find_target_layer(boosted_model),\"DN169_val_neg\", site = sites[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for layer in model.layers[:595]:\n",
    "#     layer.trainable = True\n",
    "# for layer in model.layers[595:]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# for i, layer in enumerate(model.layers):\n",
    "#     print(i, layer.name, layer.trainable)\n",
    "\n",
    "# datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=30,horizontal_flip=True)\n",
    "# traingen = datagen.flow(train_X, train_y, batch_size=32,shuffle=True)\n",
    "\n",
    "# model.compile(optimizer=optimizers.Adam(learning_rate=1e-7), loss='binary_crossentropy', metrics=['accuracy',AUC()])\n",
    "\n",
    "# results_post=model.fit(traingen,validation_data=(val_X, val_y),steps_per_epoch=traingen.n//traingen.batch_size,validation_batch_size=32,epochs=10,verbose=1)\n",
    "\n",
    "# for layer in model.layers[:595]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[595:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# for i, layer in enumerate(model.layers):\n",
    "#     print(i, layer.name, layer.trainable)\n",
    "\n",
    "# datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=30,horizontal_flip=True)\n",
    "# traingen = datagen.flow(train_X, train_y, batch_size=32,shuffle=True)\n",
    "\n",
    "# model.compile(optimizer=optimizers.Adam(learning_rate=1e-7), loss='binary_crossentropy', metrics=['accuracy',AUC()])\n",
    "\n",
    "# results_post=model.fit(traingen,validation_data=(val_X, val_y),steps_per_epoch=traingen.n//traingen.batch_size,validation_batch_size=32,epochs=10,verbose=1)\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=60,horizontal_flip=True)\n",
    "# traingen = datagen.flow(train_X, train_y, batch_size=16,shuffle=True)\n",
    "\n",
    "# opt = optimizers.Adam(learning_rate=0.0001)\n",
    "# model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy',AUC()])\n",
    "# # print(model.summary())\n",
    "# results_pre=model.fit(traingen,validation_data=(val_X, val_y),steps_per_epoch=traingen.n//traingen.batch_size,validation_batch_size=16,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# # After training, get predictions for the validation set\n",
    "# val_preds_prob = model.predict(val_X)  # shape: (num_samples, 1)\n",
    "# val_preds = (val_preds_prob > 0.5).astype(np.int32).ravel()  # convert probabilities to binary predictions\n",
    "\n",
    "# # Compute Cohen's kappa\n",
    "# kappa = cohen_kappa_score(val_y, val_preds)\n",
    "# print(\"Cohen's kappa on the validation set:\", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers[:595]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[595:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# for i, layer in enumerate(model.layers):\n",
    "#     print(i, layer.name, layer.trainable)\n",
    "\n",
    "# # for i, layer in enumerate(model.layers):\n",
    "# #     print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# results_pre_df = pd.DataFrame(results_pre.history)\n",
    "# # results_post_df = pd.DataFrame(results_post.history)\n",
    "# results_df = results_pre_df  #.append(results_post_df,sort=False)\n",
    "\n",
    "# with open('DN169_globalavgpool_2dense1024_aug_metrics.csv', 'w') as f:\n",
    "#     results_df.to_csv(f)\n",
    "\n",
    "# fpr, tpr, threshold = roc_curve(val_y,model.predict(val_X))\n",
    "# fpr = np.array(fpr)\n",
    "# tpr = np.array(tpr)\n",
    "# fpr_tpr = np.stack((fpr,tpr),axis=1)\n",
    "# header=['fpr','tpr']\n",
    "# with open('DN169_globalavgpool_2dense1024_aug_AUC.csv', 'w') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow(header)\n",
    "#     writer.writerows(fpr_tpr)\n",
    "\n",
    "# kappa_conf=[]\n",
    "\n",
    "# for n in range(17):\n",
    "#     print(kappa_conf)\n",
    "#     kappa_conf_temp=[n]\n",
    "#     val_X_mask=mask_images(val_X,24,n)\n",
    "#     kappa_conf_temp.append(cohen_kappa(y_prob=model.predict(val_X_mask),y_truth=val_y))\n",
    "#     conf_temp=confusion_matrix(val_y,np.round(model.predict(val_X_mask)))\n",
    "#     kappa_conf_temp.extend(conf_temp[0])\n",
    "#     kappa_conf_temp.extend(conf_temp[1])\n",
    "#     kappa_conf.append(kappa_conf_temp)\n",
    "\n",
    "# header=['masking','kappa','tn','fp','fn','tp']\n",
    "# with open('DN169_globalavgpool_2dense1024_aug_kappa_conf.csv', 'w') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow(header)\n",
    "#     writer.writerows(kappa_conf)\n",
    "\n",
    "# print(find_target_layer(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kappa_conf=[]\n",
    "\n",
    "# for site in [\"WRIST\",\"SHOULDER\",\"HUMERUS\",\"HAND\",\"FOREARM\",\"FINGER\",\"ELBOW\"]:\n",
    "for site in [\"FINGER\"]:\n",
    "    val_X, val_y = load_val_data(site,image_size,color_mode)\n",
    "    kappa_conf_temp=[site]\n",
    "    kappa_conf_temp.append(accuracy_score(val_y,np.round(model.predict(val_X))))\n",
    "    kappa_conf_temp.append(cohen_kappa(y_prob=model.predict(val_X),y_truth=val_y))\n",
    "    conf_temp=confusion_matrix(val_y,np.round(model.predict(val_X)))\n",
    "    kappa_conf_temp.extend(conf_temp[0])\n",
    "    kappa_conf_temp.extend(conf_temp[1])\n",
    "    kappa_conf.append(kappa_conf_temp)\n",
    "    fpr, tpr, threshold = roc_curve(val_y,model.predict(val_X))\n",
    "    fpr = np.array(fpr)\n",
    "    tpr = np.array(tpr)\n",
    "    fpr_tpr = np.stack((fpr,tpr),axis=1)\n",
    "    header=['fpr','tpr']\n",
    "    with open('DN169_globalavgpool_2dense1024_aug_AUC_'+site+'.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(fpr_tpr)\n",
    "\n",
    "header=['site','accuracy','kappa','tn','fp','fn','tp']\n",
    "with open('DN169_globalavgpool_2dense1024_aug_metrics_sites.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(kappa_conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
